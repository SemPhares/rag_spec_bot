{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zn10Rn-noLL"
      },
      "outputs": [],
      "source": [
        "# me connecter à mon compte github\n",
        "!git clone -b dev https://github.com/SemPhares/rag_spec_bot.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "# !/usr/local/bin/ollama serve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU7spDdcnjKq",
        "outputId": "5a256b2f-24c7-4906-e2db-42e20909b1cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Downloading ollama...\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install package and load the extension\n",
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5OuAhtlpej3",
        "outputId": "1e88a3b8-d4c5-40cd-b7f6-8ed7229edd1f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colab-xterm\n",
            "  Downloading colab_xterm-0.2.0-py3-none-any.whl (115 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ptyprocess~=0.7.0 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (0.7.0)\n",
            "Requirement already satisfied: tornado>5.1 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (6.3.3)\n",
            "Installing collected packages: colab-xterm\n",
            "Successfully installed colab-xterm-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "e7bebRKDBdJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjW4Ra1em1jT",
        "outputId": "7a6ee54c-ef2d-4299-8dea-3cc567202416"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('rag_spec_bot')"
      ],
      "metadata": {
        "id": "VmHgMAXlurkO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/rag_spec_bot')\n",
        "sys.path.append('/content/rag_spec_bot/app/specbot/doc_loader')\n",
        "sys.path.append('/content/rag_spec_bot/app/specbot/model_api')\n",
        "sys.path.append('/content/rag_spec_bot/app/specbot/utils')"
      ],
      "metadata": {
        "id": "myJQLusnydGF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cycx4FXmu6z7",
        "outputId": "9cc66c11-622a-4250-a146-d1558fb9efd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip install -qr requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"unstructured[all-docs]\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "WgecI-wyv1_8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from app.specbot.doc_loader.loader import CustomeLoader"
      ],
      "metadata": {
        "id": "lH-tRJJ1tUYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = CustomeLoader(filename_list=['download.png'],\n",
        "                     tempfile_path_list=['/content/rag_spec_bot/data/download.png']).load()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E9Lq3Esay-Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs.__len__()"
      ],
      "metadata": {
        "id": "Zxim6g4ty-No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from app.specbot.model_api.llm_typing import llm_input"
      ],
      "metadata": {
        "id": "wVpNF8IM8tW7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = llm_input(model_name = 'llama3', input= 'QUELS SONT les facteures accelerateurs des llm' )"
      ],
      "metadata": {
        "id": "KtBYRsQLL8ja"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from app.specbot.model_api.ollama_model import ask_ollama, ollama_caption_image\n",
        "from app.specbot.model_api.llamacpp_model import ask_llmcpp"
      ],
      "metadata": {
        "id": "sPRl_NMTL8hM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from app.specbot.doc_loader.lodaer_utils import caption_single_image"
      ],
      "metadata": {
        "id": "gY9DmLglsX3h"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/rag_spec_bot/data/download.png'"
      ],
      "metadata": {
        "id": "l51q4H6hsTqT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caption_single_image(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "voehsLAcsuXA",
        "outputId": "996bad47-9a6f-4da9-ae81-aed53240eb86"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-25 14:08:33,390 - RAG - INFO - Processing image: /content/rag_spec_bot/data/download.png\n",
            "INFO:RAG:Processing image: /content/rag_spec_bot/data/download.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'Config' has no attribute 'EXTRACTED_IMAGE_PROMPT'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-11893465efc6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcaption_single_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/rag_spec_bot/app/specbot/doc_loader/lodaer_utils.py\u001b[0m in \u001b[0;36mcaption_single_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing image: {image_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mimage_bs4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     caption_input = llama_cpp_image_input(input=Config.EXTRACTED_IMAGE_PROMPT,\n\u001b[0m\u001b[1;32m    140\u001b[0m                                           \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE_MODEL_REPO_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                                           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE_MODEL_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'Config' has no attribute 'EXTRACTED_IMAGE_PROMPT'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_ollama(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsPliB4dlZcp",
        "outputId": "a080535c-7a4d-4287-ae8d-c548bc41c9c6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "llm_output(model_name='llama3', response=\"Les LLM (Large Language Models) sont entraînées avec une grande quantité de données et utilisent diverses techniques pour améliorer leur performance. Voici quelques-unes des facteurs qui peuvent accélérer l'apprentissage d'un modèle de langage :\\n\\n1. **Taille du dataset** : Plus le jeu de données est grand, plus il y a de possibilités pour les modèles de découvrir les relations et les patterns dans la langue.\\n2. **Qualité du dataset** : Un jeu de données de haute qualité, avec des exemples bien formattés et représentatifs de la langue cible, peut aider à améliorer l'apprentissage du modèle.\\n3. **Architecture du modèle** : Les modèles plus complexes, tels que les réseaux neuronaux convolutionnels (CNN) ou les réseaux recurrents (RNN), peuvent être plus efficaces pour apprendre des patterns dans la langue.\\n4. **Nombre d'itérations de l'algorithme d'apprentissage** : Plus le modèle est entraîné, plus il peut apprendre et améliorer sa performance.\\n5. **Taille du batch** : Le choix judicieux de la taille du batch (nombre d'exemples utilisés pour chaque itération) peut influencer l'accélération de l'apprentissage.\\n6. **Optimisation des hyper-paramètres** : La sélection optimale des hyper-paramètres, tels que le taux d'apprentissage ou les poids initiaux du modèle, peut améliorer la performance et accélérer l'apprentissage.\\n7. **Techniques de régularisation** : Les techniques de régularisation telles que la L1 ou la L2 regularization peuvent aider à réduire l'overfitting (surapprentissage) et à améliorer la généralisation du modèle.\\n8. **Utilisation d'un pré-entraînement** : Un pré-entraînement avec un jeu de données plus petit peut aider le modèle à apprendre des patterns fondamentaux avant de passer au grand entraînement.\\n9. **Parallélisme et distribution** : L'utilisation de processeurs ou de serveurs pour distribuer l'apprentissage peut accélérer significativement la formation du modèle.\\n10. **Mise en œuvre efficace des algorithmes d'entraînement** : La mise en œuvre optimale des algorithmes d'entraînement, tels que les algorithme de gradient descent ou Adam, peut également influencer l'accélération de l'apprentissage.\\n\\nIl est important de noter que ces facteurs peuvent varier en fonction du modèle et de la tâche spécifique.\")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Ju6SFcHL8dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbjeVOQvuG3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_W2yQDCduG0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_Dt7bnPL8ad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}